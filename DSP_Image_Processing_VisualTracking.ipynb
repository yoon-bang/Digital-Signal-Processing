{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"fGOVXGHNouUV","executionInfo":{"status":"ok","timestamp":1685887385075,"user_tz":-540,"elapsed":488,"user":{"displayName":"방윤하","userId":"13989411945591696000"}}},"source":["import numpy as np\n","import cv2\n","import os\n","from google.colab.patches import cv2_imshow"],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/DigitalSignalProcessing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fa-ov1STklko","executionInfo":{"status":"ok","timestamp":1685887420072,"user_tz":-540,"elapsed":35006,"user":{"displayName":"방윤하","userId":"13989411945591696000"}},"outputId":"812f45e5-60cd-46ef-caf3-6a16adfd5ab9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/DigitalSignalProcessing\n"]}]},{"cell_type":"code","metadata":{"id":"5VaPT7rzo6jD","executionInfo":{"status":"ok","timestamp":1685887420073,"user_tz":-540,"elapsed":6,"user":{"displayName":"방윤하","userId":"13989411945591696000"}}},"source":["# used for linear mapping...\n","def linear_mapping(img):\n","    return (img - img.min()) / (img.max() - img.min())\n","\n","# pre-processing the image...\n","def pre_process(img):\n","    # get the size of the img...\n","    height, width = img.shape\n","    # intensity normalization\n","    img = np.log(img + 1)\n","    img = (img - np.mean(img)) / (np.std(img) + 1e-5)\n","    # Apply the cosine window\n","    window = window_func_2d(height, width)\n","    img = img * window\n","\n","    return img\n","\n","# cosine window generation function\n","def window_func_2d(height, width):\n","    win_col = np.hanning(width)\n","    win_row = np.hanning(height)\n","    mask_col, mask_row = np.meshgrid(win_col, win_row)\n","\n","    win = mask_col * mask_row\n","\n","    return win\n","\n","def random_warp(img):\n","    a = -180 / 16\n","    b = 180 / 16\n","    r = a + (b - a) * np.random.uniform()\n","    # rotate the image...\n","    matrix_rot = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), r, 1)\n","    img_rot = cv2.warpAffine(np.uint8(img * 255), matrix_rot, (img.shape[1], img.shape[0]))\n","    img_rot = img_rot.astype(np.float32) / 255\n","    return img_rot"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnN0WUa9rDSB","executionInfo":{"status":"ok","timestamp":1685887420073,"user_tz":-540,"elapsed":5,"user":{"displayName":"방윤하","userId":"13989411945591696000"}}},"source":["# alpha value\n","lr = 0.125\n","# variance for the target Gaussian response\n","sigma = 100\n","# number of frames to be used for the pre-training\n","num_pretrain =  1\n","# rotation augmentation?\n","rotate = True"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PfKCEnJoyL1","executionInfo":{"status":"ok","timestamp":1685887420074,"user_tz":-540,"elapsed":5,"user":{"displayName":"방윤하","userId":"13989411945591696000"}}},"source":["class mosse:\n","    def __init__(self, lr, sigma, num_pretrain, rotate, img_path):\n","        # get arguments..\n","        self.lr = lr\n","        self.sigma = sigma\n","        self.num_pretrain = num_pretrain\n","        self.rotate = rotate\n","\n","        self.img_path = img_path\n","        # get the img lists...\n","        self.frame_lists = self._get_img_lists(self.img_path)\n","        self.frame_lists.sort()\n","\n","\n","    # pre train the filter on the first frame...\n","    def _pre_training(self, init_frame, G):\n","        height, width = G.shape\n","        fi = cv2.resize(init_frame, (width, height))\n","        # pre-process img..\n","        fi = pre_process(fi)\n","        Ai = G * np.conjugate(np.fft.fft2(fi))\n","        Bi = np.fft.fft2(init_frame) * np.conjugate(np.fft.fft2(init_frame))\n","\n","        # pre-training sequence\n","        for _ in range(self.num_pretrain):\n","            if self.rotate:\n","                fi = pre_process(random_warp(init_frame))\n","            else:\n","                fi = pre_process(init_frame)\n","            Ai = Ai + G * np.conjugate(np.fft.fft2(fi))\n","            Bi = Bi + np.fft.fft2(fi) * np.conjugate(np.fft.fft2(fi))\n","        \n","        return Ai, Bi\n","    \n","    # start to do the object tracking...\n","    def start_tracking(self, init_gt):\n","        # get the image of the first frame... (read as gray scale image...)\n","        init_img = cv2.imread(self.frame_lists[0])\n","        init_frame = cv2.cvtColor(init_img, cv2.COLOR_BGR2GRAY)\n","        init_frame = init_frame.astype(np.float32)\n","\n","        # get the init ground truth.. [x, y, width, height]\n","        # start to draw the gaussian response...\n","        response_map = self._get_gauss_response(init_frame, init_gt)\n","\n","        # start to create the training set ...\n","        # get the goal..\n","        g = response_map[init_gt[1]:init_gt[1]+init_gt[3], init_gt[0]:init_gt[0]+init_gt[2]]\n","        fi = init_frame[init_gt[1]:init_gt[1]+init_gt[3], init_gt[0]:init_gt[0]+init_gt[2]]\n","        G = np.fft.fft2(g)\n","\n","        # start to do the pre-training...\n","        Ai, Bi = self._pre_training(fi, G)\n","\n","        # start the tracking...\n","        for idx in range(len(self.frame_lists)):\n","            current_frame = cv2.imread(self.frame_lists[idx])\n","            frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n","            frame_gray = frame_gray.astype(np.float32)\n","            if idx == 0:\n","                Ai = self.lr * Ai\n","                Bi = self.lr * Bi\n","                pos = init_gt.copy()\n","                clip_pos = np.array([pos[0], pos[1], pos[0]+pos[2], pos[1]+pos[3]]).astype(np.int64)\n","            else:\n","                Hi = Ai / Bi\n","                fi = frame_gray[clip_pos[1]:clip_pos[3], clip_pos[0]:clip_pos[2]]\n","                fi = pre_process(cv2.resize(fi, (init_gt[2], init_gt[3])))\n","                Gi = Hi * np.fft.fft2(fi)\n","                gi = linear_mapping(np.fft.ifft2(Gi))\n","                # find the max pos...\n","                max_value = np.max(gi)\n","                max_pos = np.where(gi == max_value)\n","                dy = int(np.mean(max_pos[0]) - gi.shape[0] / 2)\n","                dx = int(np.mean(max_pos[1]) - gi.shape[1] / 2)\n","                \n","                # update the position...\n","                pos[0] = pos[0] + dx\n","                pos[1] = pos[1] + dy\n","\n","                # trying to get the clipped position [xmin, ymin, xmax, ymax]\n","                clip_pos[0] = np.clip(pos[0], 0, current_frame.shape[1])\n","                clip_pos[1] = np.clip(pos[1], 0, current_frame.shape[0])\n","                clip_pos[2] = np.clip(pos[0]+pos[2], 0, current_frame.shape[1])\n","                clip_pos[3] = np.clip(pos[1]+pos[3], 0, current_frame.shape[0])\n","                clip_pos = clip_pos.astype(np.int64)\n","\n","                # get the current fi..\n","                fi = frame_gray[clip_pos[1]:clip_pos[3], clip_pos[0]:clip_pos[2]]\n","                fi = pre_process(cv2.resize(fi, (init_gt[2], init_gt[3])))\n","                # online update...\n","                Ai = self.lr * (G * np.conjugate(np.fft.fft2(fi))) + (1 - self.lr) * Ai\n","                Bi = self.lr * (np.fft.fft2(fi) * np.conjugate(np.fft.fft2(fi))) + (1 - self.lr) * Bi\n","            \n","            # visualize the tracking process...\n","            if idx%20 == 0:\n","              \n","              cv2.rectangle(current_frame, (pos[0], pos[1]), (pos[0]+pos[2], pos[1]+pos[3]), (255, 0, 0), 2)\n","              cv2_imshow(current_frame)\n","              #cv2.waitKey(100)\n","\n","\n","    # get the ground-truth gaussian reponse...\n","    def _get_gauss_response(self, img, gt):\n","        # get the shape of the image..\n","        height, width = img.shape\n","        # get the mesh grid...\n","        xx, yy = np.meshgrid(np.arange(width), np.arange(height))\n","        # get the center of the object...\n","        center_x = gt[0] + 0.5 * gt[2]\n","        center_y = gt[1] + 0.5 * gt[3]\n","        # cal the distance...\n","        dist = (np.square(xx - center_x) + np.square(yy - center_y)) / (2 * self.sigma)\n","        # get the response map...\n","        response = np.exp(-dist)\n","        # normalize...\n","        response = linear_mapping(response)\n","        return response\n","\n","    # it will extract the image list \n","    def _get_img_lists(self, img_path):\n","        frame_list = []\n","        for frame in os.listdir(img_path):\n","            if os.path.splitext(frame)[1] == '.jpg':\n","                frame_list.append(os.path.join(img_path, frame)) \n","        return frame_list\n","    \n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JXY3EtYgtSiUi5-RcFs53EIrJWsgCoJ1"},"id":"lsrhRLntpAdt","outputId":"ee81cf7a-02ea-4a49-9e9e-9a0f7cef4a27","executionInfo":{"status":"ok","timestamp":1685887432036,"user_tz":-540,"elapsed":11966,"user":{"displayName":"방윤하","userId":"13989411945591696000"}}},"source":["img_path = './surfer'\n","tracker = mosse(lr, sigma, num_pretrain, rotate, img_path)\n","tracker.start_tracking([250, 100, 120, 180])"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"DmyywwZerlpZ","executionInfo":{"status":"ok","timestamp":1685887432036,"user_tz":-540,"elapsed":14,"user":{"displayName":"방윤하","userId":"13989411945591696000"}}},"source":[],"execution_count":6,"outputs":[]}]}